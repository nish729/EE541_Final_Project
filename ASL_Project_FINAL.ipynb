{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "import random\n",
    "import copy\n",
    "from PIL import Image\n",
    "from torchviz import make_dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Data from HDF5 File\n",
    "file = 'ASLImprovedDataset.hdf5'\n",
    "\n",
    "# Read Data from HDF5 File\n",
    "with h5py.File(file, 'r') as df:\n",
    "    x_train_pre_norm = np.array(df['x_train'])\n",
    "    y_train_pre_norm = np.array(df['y_train'])\n",
    "    x_test_pre_norm = np.array(df['x_test'])\n",
    "    y_test_pre_norm = np.array(df['y_test'])\n",
    "\n",
    "# Normalize the data\n",
    "x_train = np.copy(x_train_pre_norm)\n",
    "x_train = x_train.astype('float32')/255\n",
    "y_train = np.copy(y_train_pre_norm)\n",
    "\n",
    "x_test = np.copy(x_test_pre_norm)\n",
    "x_test = x_test.astype('float32')/255\n",
    "y_test = np.copy(y_test_pre_norm)\n",
    "\n",
    "\n",
    "tv_transforms = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2,\n",
    "                           saturation=0.2, hue=0.2),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Extracts Training and Validation Set\n",
    "class ASLSetTV(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels, forms):\n",
    "        self.labels = labels\n",
    "        self.images = images\n",
    "        self.tform = forms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]\n",
    "        lab = self.labels[index]\n",
    "        X = self.tform(torch.from_numpy(img))\n",
    "        Y = lab\n",
    "        return X, Y\n",
    "\n",
    "# Extracts Test Set\n",
    "class ASLSetTest(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.labels = labels\n",
    "        self.images = images\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = self.images[index]\n",
    "        lab = self.labels[index]\n",
    "        X = torch.from_numpy(img)\n",
    "        Y = lab\n",
    "        return X, Y\n",
    "\n",
    "\n",
    "classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O','P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
    "\n",
    "# # Split Training Data and Validation Data\n",
    "# train_to_val_ratio = 0.80\n",
    "# train_size = int(train_to_val_ratio * len(tv_set))\n",
    "# val_size = len(tv_set) - train_size\n",
    "# train_set, val_set = torch.utils.data.random_split(tv_set, [train_size, val_size])\n",
    "\n",
    "\n",
    "# Load Training and Validation Sets\n",
    "train_set = ASLSetTV(x_train, y_train, tv_transforms)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True)\n",
    "# val_loader = torch.utils.data.DataLoader(val_set, batch_size = 100, shuffle = False)\n",
    "\n",
    "\n",
    "# Load Test Set\n",
    "test_set = ASLSetTest(x_test, y_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=100, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.Linear1 = nn.Linear(3*125*125, 1024)\n",
    "        self.Linear2 = nn.Linear(1024, 256)\n",
    "        self.Linear3 = nn.Linear(256, 29)\n",
    "        self.dropout = nn.Dropout(p = 0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3*125*125)\n",
    "        \n",
    "        # Hidden Layer 1\n",
    "        x = self.Linear1(x)\n",
    "        x = nn.ReLU(inplace = True)(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Hidden Layer 2\n",
    "        x = self.Linear2(x)\n",
    "        x = nn.ReLU(inplace = True)(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # Output Layer\n",
    "        x = self.Linear3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom CNN Model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_layer1 = nn.Conv2d(3, 32, 3, padding = 1)\n",
    "        self.conv_layer2 = nn.Conv2d(32, 64, 3, stride = 1, padding = 1)\n",
    "        self.conv_layer3 = nn.Conv2d(64, 128, 3, stride = 1, padding = 1)\n",
    "        self.conv_layer4 = nn.Conv2d(128, 256, 3, stride = 1, padding = 1)\n",
    "\n",
    "        self.pool_layer = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "\n",
    "        self.bn_layer1 = nn.BatchNorm2d(32)\n",
    "        self.bn_layer2 = nn.BatchNorm2d(64)\n",
    "        self.bn_layer3 = nn.BatchNorm2d(128)\n",
    "        self.bn_layer4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.linear1 = nn.Linear(256 * 7 * 7, 512)\n",
    "        self.linear2 = nn.Linear(512, 128)\n",
    "        self.linear3 = nn.Linear(128, 29)\n",
    "\n",
    "        self.dropout = nn.Dropout(p = 0.3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        # Convolutional Layer 1\n",
    "        x = self.conv_layer1(x)\n",
    "        x = nn.ReLU(inplace=True)(x)\n",
    "        x = self.pool_layer(x)\n",
    "        x = self.bn_layer1(x)\n",
    "\n",
    "        # Convolutional Layer 2\n",
    "        x = self.conv_layer2(x)\n",
    "        x = nn.ReLU(inplace=True)(x)\n",
    "        x = self.pool_layer(x)\n",
    "        x = self.bn_layer2(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Convolutional Layer 3\n",
    "        x = self.conv_layer3(x)\n",
    "        x = nn.ReLU(inplace=True)(x)\n",
    "        x = self.pool_layer(x)\n",
    "        x = self.bn_layer3(x)\n",
    "\n",
    "        # Convolutional Layer 4\n",
    "        x = self.conv_layer4(x)\n",
    "        x = nn.ReLU(inplace=True)(x)\n",
    "        x = self.pool_layer(x)\n",
    "        x = self.bn_layer4(x)\n",
    "        \n",
    "        # Linear Layer 1\n",
    "        x = torch.flatten(x,1)\n",
    "        x = self.dropout(x)        \n",
    "        x = self.linear1(x)\n",
    "        x = nn.ReLU(inplace=True)(x)\n",
    "\n",
    "        # Linear Layer 2\n",
    "        x = self.linear2(x)\n",
    "        x = nn.ReLU(inplace=True)(x)\n",
    "\n",
    "        # Linear Layer 3\n",
    "        x = self.linear3(x)\n",
    "        \n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Accuracy Curve and Learning Curve\n",
    "def acc_LC_plotter(train_accuracy_list,val_accuracy_list,train_loss_list,val_loss_list):\n",
    "    # Plotting Accuracy\n",
    "    plt.rcParams['figure.figsize'] = [6, 4]\n",
    "    plt.plot(np.arange(num_epochs),train_accuracy_list, label = \"Training Data\")\n",
    "    plt.plot(np.arange(num_epochs),val_accuracy_list, label = \"Testing Data\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Number of Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Accuracy of Model\")\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    # Plotting Log-Loss\n",
    "    plt.rcParams['figure.figsize'] = [6, 4]\n",
    "    plt.plot(np.arange(num_epochs),train_loss_list, label = \"Training Data\")\n",
    "    plt.plot(np.arange(num_epochs),val_loss_list, label = \"Testing Data\")\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Number of Epochs\")\n",
    "    plt.ylabel(\"Log-Loss\")\n",
    "    plt.title(\"Learning Curve\")\n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Confusion Matrix\n",
    "def cfm_plotter(gt_label,pred_label):\n",
    "    plt.rcParams['figure.figsize'] = [10, 10]\n",
    "    conf_matrix = confusion_matrix(np.array(gt_label), np.array(pred_label))\n",
    "    width, height = conf_matrix.shape\n",
    "    plt.figure()\n",
    "    sns.heatmap(conf_matrix, annot = True, fmt = 'd', cmap = 'Blues')\n",
    "\n",
    "    # Formatting the Confusion Matrix\n",
    "    plt.xticks(np.arange(width) + 0.5, classes[:width],  rotation=45)\n",
    "    plt.yticks(np.arange(height) + 0.5, classes[:height], rotation='horizontal')\n",
    "    plt.xlabel(\"True Labels\")\n",
    "    plt.ylabel(\"Predicted Labels\")\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model definition\n",
    "def overall_model(model_variation, learning_rate, L2_coeff, num_epochs):\n",
    "    # Speed Up Training Time with MPS\n",
    "    device = torch.device('mps' if torch.has_mps else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "    ## Choosing which model to run\n",
    "    # Custom MLP\n",
    "    if (model_variation == \"MLP\"):\n",
    "        model = MLP()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, weight_decay = L2_coeff)\n",
    "\n",
    "    # Custon CNN\n",
    "    if (model_variation == \"CNN\"):\n",
    "        model = CNN()\n",
    "        optimizer = torch.optim.NAdam(model.parameters(), lr = learning_rate, weight_decay = L2_coeff)\n",
    "        \n",
    "    # Resnet18\n",
    "    if (model_variation == \"resnet\"):\n",
    "        model = models.resnet18()\n",
    "        model.fc = nn.Linear(model.fc.in_features, 29)  # use this for resnet\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = L2_coeff)\n",
    "\n",
    "    # MobileNetV2\n",
    "    if (model_variation == \"mobilenet\"): \n",
    "        model = models.mobilenet_v2()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = L2_coeff)\n",
    "\n",
    "    # SqueezeNet\n",
    "    if (model_variation == \"squeezenet\"): \n",
    "        model = models.squeezenet1_0()\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay = L2_coeff)\n",
    "\n",
    "\n",
    "    # Set Up Model\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list = [], [], [], []\n",
    "    overall_total = len(train_loader)\n",
    "    min_loss = np.Inf\n",
    "    \n",
    "    # Training and Testing the Model\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc, train_total = 0, 0, 0\n",
    "        start_time = time()\n",
    "\n",
    "        # Training Mode\n",
    "        model.train()\n",
    "        for images_train, labels_train in tqdm(train_loader, desc = 'Training Set', unit = 'Batches'):\n",
    "            # Moving to MPS\n",
    "            images_train = images_train.to(device)\n",
    "            labels_train = labels_train.to(device)\n",
    "\n",
    "            # Forward Inference\n",
    "            optimizer.zero_grad()\n",
    "            outputs_train = model(images_train)\n",
    "            # make_dot(outputs_train, params = dict(model.named_parameters())).render(model_variation, format = \"png\")\n",
    "            loss = criterion(outputs_train, labels_train)\n",
    "\n",
    "            # Backward Propagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate Mtrics\n",
    "            train_loss += loss.item()\n",
    "            _,pred = torch.max(outputs_train, dim = 1)\n",
    "            train_acc += torch.sum(pred == labels_train).item()\n",
    "            train_total += labels_train.size(0)\n",
    "\n",
    "        # Prep for Plotting\n",
    "        train_accuracy_list.append(100 * train_acc / train_total)\n",
    "        train_loss_list.append(train_loss/ overall_total)\n",
    "        \n",
    "        #Validation/Testing  \n",
    "        val_loss, val_acc, val_total = 0, 0, 0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "            for images_val, labels_val in tqdm(test_loader, desc = 'Validation Set', unit = 'Batches'):\n",
    "                # Moving to MPS\n",
    "                images_val = images_val.to(device)\n",
    "                labels_val = labels_val.to(device)\n",
    "\n",
    "                # Forward Inference\n",
    "                outputs_val = model(images_val)\n",
    "                loss_val = criterion(outputs_val, labels_val)\n",
    "\n",
    "                # Calculate Metrics\n",
    "                val_loss += loss_val.item() \n",
    "                _,pred_val = torch.max(outputs_val, dim = 1)\n",
    "                val_acc += torch.sum(pred_val == labels_val).item()\n",
    "                val_total += labels_val.size(0)\n",
    "\n",
    "                # For Confusion Matrix\n",
    "                _, predicted = torch.max(outputs_val.data, 1)\n",
    "                y_pred.extend(predicted.cpu().numpy())\n",
    "                y_true.extend(labels_val.cpu().numpy())\n",
    "                \n",
    "\n",
    "            # Prep for Plotting\n",
    "            val_accuracy_list.append(100 * val_acc / val_total)\n",
    "            val_loss_list.append(val_loss / len(test_loader))\n",
    "            checkpoint = val_loss < min_loss\n",
    "\n",
    "            print(f\"[{epoch+1}/{num_epochs}], Training Accuracy: {100 * train_acc/train_total:.4f}%, Testing Accuracy: {100 * val_acc/val_total:.4f}%, \" + \n",
    "            f\" Training Loss: {np.mean(train_loss_list):.4f}, Test loss: {np.mean(val_loss_list):.4f}. Time per epoch: {(time() - start_time):.2} seconds\")\n",
    "            iter_time = time()\n",
    "\n",
    "            if checkpoint:\n",
    "                min_loss = val_loss\n",
    "                if (model_variation == 'MLP'):\n",
    "                    torch.save(model.state_dict(), 'MLP.pt')\n",
    "                if (model_variation == 'CNN'):\n",
    "                    torch.save(model.state_dict(), 'CNN.pt')\n",
    "                if (model_variation == 'resnet'):\n",
    "                    torch.save(model.state_dict(), 'resnet.pt')\n",
    "                if (model_variation == 'mobilenet'):\n",
    "                    torch.save(model.state_dict(), 'mobilenet.pt')\n",
    "                if (model_variation == 'squeezenet'):\n",
    "                    torch.save(model.state_dict(), 'squeezenet.pt')\n",
    "\n",
    "    return train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list, y_pred, y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom MLP Network\n",
    "\n",
    "# learning_rate = 5e-4\n",
    "# L2_coeff = 1e-4\n",
    "# num_epochs = 5\n",
    "# model_variation = \"MLP\"\n",
    "\n",
    "# train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list, predicted_label, gt_label = overall_model(model_variation, learning_rate, L2_coeff, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Accuracy, Learning Curve, and Confusion Matrix for Custom MLP\n",
    "\n",
    "# acc_LC_plotter(train_accuracy_list,val_accuracy_list,train_loss_list,val_loss_list)\n",
    "# cfm_plotter(gt_label,predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Custom CNN Network\n",
    "\n",
    "# learning_rate = 1e-3\n",
    "# L2_coeff = 5e-4\n",
    "# num_epochs = 3\n",
    "# model_variation = \"CNN\"\n",
    "\n",
    "# train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list, predicted_label, gt_label = overall_model(model_variation, learning_rate, L2_coeff, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Accuracy, Learning Curve, and Confusion Matrix for Custom CNN\n",
    "\n",
    "# acc_LC_plotter(train_accuracy_list,val_accuracy_list,train_loss_list,val_loss_list)\n",
    "# cfm_plotter(gt_label,predicted_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ResNet18 Network\n",
    "\n",
    "# learning_rate = 5e-4\n",
    "# L2_coeff = 1e-4\n",
    "# num_epochs = 10\n",
    "# model_variation = \"resnet\"\n",
    "\n",
    "# train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list, predicted_label, gt_label = overall_model(model_variation, learning_rate, L2_coeff, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Accuracy, Learning Curve, and Confusion Matrix for ResNet18\n",
    "\n",
    "# acc_LC_plotter(train_accuracy_list,val_accuracy_list,train_loss_list,val_loss_list)\n",
    "# cfm_plotter(gt_label,predicted_label)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MobileNetV2 Network\n",
    "\n",
    "# learning_rate = 5e-4\n",
    "# L2_coeff = 1e-4\n",
    "# num_epochs = 10\n",
    "# model_variation = \"mobilenet\"\n",
    "\n",
    "# train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list, predicted_label, gt_label = overall_model(model_variation, learning_rate, L2_coeff, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Accuracy, Learning Curve, and Confusion Matrix for MobileNetV2\n",
    "\n",
    "# acc_LC_plotter(train_accuracy_list,val_accuracy_list,train_loss_list,val_loss_list)\n",
    "# cfm_plotter(gt_label,predicted_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SqueezeNet Network\n",
    "\n",
    "# learning_rate = 5e-4\n",
    "# L2_coeff = 1e-4\n",
    "# num_epochs = 1\n",
    "# model_variation = \"squeezenet\"\n",
    "\n",
    "# train_loss_list, val_loss_list, train_accuracy_list, val_accuracy_list, predicted_label, gt_label = overall_model(model_variation, learning_rate, L2_coeff, num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot Accuracy, Learning Curve, and Confusion Matrix for SqueezeNet\n",
    "\n",
    "# acc_LC_plotter(train_accuracy_list,val_accuracy_list,train_loss_list,val_loss_list)\n",
    "# cfm_plotter(gt_label,predicted_label)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d2ad059d03ecd2ca5d98a467a31e977b400ce30d3630580c08e63946179bd22"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
